In computer architecture, Amdahl's law (or Amdahl's rule) is a theoretical limit on the speed of a computer system as the number of simultaneous tasks or operations increases. The law states that the maximum speedup that can be achieved from parallelization of a task is limited by the amount of work that can be divided among the available processors.  The law was formulated by IBM researcher Gene Amdahl in 1956, and has been widely used in computer performance studies. Its main application has been to determine the practical limits on the speed of computers using conventional processors.
